# ğŸª NASA Exoplanet Detection with AI

**NASA Space Apps Challenge 2025 - A World Away: Hunting for Exoplanets with AI**

An AI-powered system for detecting exoplanets from Kepler Space Telescope transit data using LightGBM machine learning.

![Python](https://img.shields.io/badge/Python-3.8+-blue)
![LightGBM](https://img.shields.io/badge/LightGBM-4.6.0-green)
![Streamlit](https://img.shields.io/badge/Streamlit-1.40.2-red)
![License](https://img.shields.io/badge/License-MIT-yellow)

## ğŸŒ Live Demo

**Try it now:** [https://spaceapps-exoplanet-detector.streamlit.app/](https://spaceapps-exoplanet-detector.streamlit.app/)

## ğŸš€ Project Overview

This project automates the detection of exoplanets from transit signals in the Kepler Space Telescope data, reducing manual vetting by astronomers. Using supervised machine learning with LightGBM, we classify Kepler Objects of Interest (KOI) as either confirmed/candidate planets or false positives.

### Key Features
- **ğŸŒ Live Web Application**: Deployed on Streamlit Cloud for instant access
- **ğŸ¯ High-Performance ML Models**: Baseline (84% accuracy, 93% ROC-AUC) and Full (87% accuracy, 94% ROC-AUC)
- **ğŸ”® Candidate Predictor**: Analyze unconfirmed KOI candidates with confidence scores
- **ğŸŒŒ 3D Visualizations**: Interactive Three.js solar system views with size comparisons
- **ğŸ“Š SHAP Explainability**: Understand which features drive each prediction
- **ğŸ›¡ï¸ Data Leakage Prevention**: Rigorous removal of 88 leakage columns for genuine learning
- **ğŸ“ˆ Interactive Dashboard**: Explore data, model performance, and make predictions

## ğŸ“Š Model Performance

### Full Model (52 features, optimized)
| Metric | Test Set Score |
|--------|-------|
| **Accuracy** | 87.4% |
| **Precision** | 86.9% |
| **Recall** | 88.0% |
| **F1-Score** | 87.4% |
| **ROC-AUC** | 94.3% |

### Baseline Model (9 core features)
| Metric | Test Set Score |
|--------|-------|
| **Accuracy** | 84.3% |
| **Precision** | 84.4% |
| **Recall** | 83.7% |
| **F1-Score** | 84.1% |
| **ROC-AUC** | 92.7% |

## ğŸ› ï¸ Installation

### Prerequisites
- Python 3.8 or higher
- pip package manager

### Setup

1. **Clone the repository**
```bash
git clone https://github.com/yourusername/nasa-exoplanet-detection.git
cd nasa-exoplanet-detection
```

2. **Install dependencies**
```bash
pip install -r requirements.txt
```

3. **Run the application**
```bash
cd src
streamlit run app.py
```

The application will open in your browser at `http://localhost:8501`

## ğŸ“ Project Structure

```
nasa-exoplanet-detection/
â”‚
â”œâ”€â”€ data/                              # Data directory
â”‚   â”œâ”€â”€ download_dataset.py            # Automatic dataset downloader
â”‚   â”œâ”€â”€ kepler_koi.csv                 # Raw Kepler KOI dataset (153 columns)
â”‚   â”œâ”€â”€ README.md                      # Dataset documentation
â”‚   â””â”€â”€ preprocessing/                 # Processed data
â”‚       â”œâ”€â”€ data_preprocessing.py      # Preprocessing pipeline
â”‚       â”œâ”€â”€ kepler_koi_preprocessed.csv # Clean dataset (77 features + label)
â”‚       â”œâ”€â”€ preprocessor.pkl           # Saved preprocessor
â”‚       â””â”€â”€ preprocessing_summary.txt  # Feature list
â”‚
â”œâ”€â”€ models/                            # Model directory
â”‚   â”œâ”€â”€ train_model.py                 # LightGBM training script
â”‚   â”œâ”€â”€ lightgbm_model.pkl             # Trained model
â”‚   â””â”€â”€ model_metrics.json             # Performance metrics
â”‚
â”œâ”€â”€ src/                               # Web application
â”‚   â””â”€â”€ app.py                         # Streamlit web application
â”‚
â”œâ”€â”€ CLAUDE.md                          # Project specifications
â”œâ”€â”€ requirements.txt                   # Python dependencies
â””â”€â”€ README.md                          # This file
```

## ğŸ”¬ Dataset

- **Source**: NASA Exoplanet Archive - Kepler Objects of Interest (KOI)
- **Download Method**: Automatic via TAP API (`cumulative` table)
- **Size**: 9,564 transit signals
- **Raw Columns**: 153 features
- **Clean Features**: 52 features (Full model) / 9 features (Baseline model)
- **Target**: Binary classification (Planet vs False Positive)
- **Class Distribution**: ~50% planets, ~50% non-planets (balanced)

### Data Leakage Prevention

We carefully removed **88 columns** that could leak classification information:
- **False positive flags** (koi_fpflag_nt, koi_fpflag_ss, koi_fpflag_co, koi_fpflag_ec)
- **Derived planet properties** (koi_prad, koi_teq, koi_insol, koi_dor, koi_incl, etc.)
- **Disposition scores** (koi_score, koi_pdisposition - vetting outputs)
- **Centroid offsets** (dikco_*, dicco_*, fwm_* - post-vetting features)
- **Model fitting outputs** (fitted parameters that use disposition)

This ensures the model learns from **genuine observational data only**.

### Feature Categories

**Baseline Model (9 features):**
- Core stellar properties: koi_steff, koi_slogg, koi_srad, koi_kepmag
- Core transit signals: koi_period, koi_depth, koi_duration, koi_impact, koi_model_snr

**Full Model (52 features):**

1. **Transit Signals**: Period, depth, duration, impact parameter
2. **Stellar Properties**: Temperature, radius, mass, surface gravity, metallicity
3. **Photometry**: Magnitudes in multiple bands (g, r, i, z, J, H, K, Kepler)
4. **Signal Statistics**: SNR, single/multiple event statistics
5. **Centroid Offsets**: Flux-weighted and difference image centroids

## ğŸ¯ Usage

### Download Dataset

```bash
cd data
python download_dataset.py
```

This downloads the complete Kepler KOI dataset (153 columns) from NASA Exoplanet Archive.

### Web Application

**Live Demo**: [https://spaceapps-exoplanet-detector.streamlit.app/](https://spaceapps-exoplanet-detector.streamlit.app/)

The web application includes 6 main tabs:

1. **ğŸ” Sample Explorer**: Interactive exploration of labeled KOIs with:
   - 3D solar system visualization (default view)
   - Star/planet size comparisons with Sun/Earth
   - Prediction results with confidence gauges
   - SHAP explainability analysis

2. **ğŸ”® Candidate Predictor**: Analyze unconfirmed candidate KOIs:
   - Batch classification of all candidates
   - Confidence distribution histogram
   - High-confidence planet identification
   - Downloadable results

3. **ğŸ“‚ Import & Predict**: Upload custom CSV data for predictions

4. **ğŸ“Š Data Explorer**: Explore dataset statistics and distributions

5. **ğŸ“ˆ Model Performance**: View detailed performance metrics across train/val/test splits

6. **ğŸ“š Documentation**: Complete project documentation and methodology

### Python API

```python
import pickle
import pandas as pd

# Load model and metrics
with open('models/lightgbm_model.pkl', 'rb') as f:
    model = pickle.load(f)

# Load preprocessor to get feature names
with open('data/preprocessing/preprocessor.pkl', 'rb') as f:
    preprocessor = pickle.load(f)

feature_names = preprocessor['feature_columns']

# Prepare your data (77 features)
# Must be preprocessed (scaled) data
features = pd.DataFrame(..., columns=feature_names)

# Make prediction
prediction = model.predict(features)
probability = model.predict_proba(features)

print(f"Classification: {'Planet' if prediction[0] == 1 else 'Non-Planet'}")
print(f"Confidence: {probability[0][1]:.1%}")
```

## ğŸ”§ Training the Model

To retrain the model with new data or parameters:

1. **Download data**: `python data/download_dataset.py`
2. **Preprocess**: `python data/preprocessing/data_preprocessing.py`
3. **Train model**: `python models/train_model.py`

The trained model will be saved to `models/lightgbm_model.pkl`

## ğŸ“ˆ Model Architecture

- **Algorithm**: LightGBM (Light Gradient Boosting Machine)
- **Type**: Binary classification
- **Data Split**: 70% train, 10% validation, 20% test (stratified)
- **Preprocessing**: StandardScaler + median imputation
- **Key Hyperparameters**:
  - n_estimators: 200
  - learning_rate: 0.05
  - max_depth: 7
  - num_leaves: 31
  - subsample: 0.8
  - colsample_bytree: 0.8

## ğŸ† NASA Space Apps Challenge 2025

This project was developed for the NASA Space Apps Challenge 2025, addressing the challenge:
**"A World Away: Hunting for Exoplanets with AI"**

### Challenge Goals Met
âœ… Automated exoplanet detection from transit data\
âœ… High-accuracy machine learning models (87% accuracy, 94% ROC-AUC)\
âœ… Rigorous data leakage prevention for genuine learning\
âœ… Complete data pipeline (download â†’ preprocess â†’ train â†’ deploy)\
âœ… Interactive 3D visualizations with size comparisons\
âœ… SHAP explainability for model interpretability\
âœ… Candidate predictor for unconfirmed KOIs\
âœ… Open-source implementation with documentation\
âœ… **Deployed web application** on Streamlit Cloud

## ğŸ“š References

- [NASA Exoplanet Archive](https://exoplanetarchive.ipac.caltech.edu/)
- [Kepler Mission](https://www.nasa.gov/mission_pages/kepler/)
- [LightGBM Documentation](https://lightgbm.readthedocs.io/)
- Assessment of Ensemble-Based Machine Learning Algorithms for Exoplanet Identification

### Citation

If you use this work, please cite:
```
NASA Exoplanet Archive (2025)
DOI: http://doi.org/10.17616/R3X31K
```

## ğŸ“„ License

This project is open source and available under the MIT License.

## ğŸ“§ Contact

For questions or collaboration opportunities, please open an issue on GitHub.

---

**Live Demo**: [https://spaceapps-exoplanet-detector.streamlit.app/](https://spaceapps-exoplanet-detector.streamlit.app/)

**Note**: This project achieves 87% accuracy and 94% ROC-AUC on clean, leakage-free data. The model learns from genuine observational features only, making it suitable for real-world exoplanet vetting workflows.